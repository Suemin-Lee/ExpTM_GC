{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMnV8g9MuZSj0gA+v3dYS8S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lherron2/thermomaps-ising/blob/main/Ising_TM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIyTPcnP31nE",
        "outputId": "efcc2f81-6709-4941-99ae-934c93466ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'thermomaps-ising'...\n",
            "remote: Enumerating objects: 235, done.\u001b[K\n",
            "remote: Counting objects: 100% (235/235), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 235 (delta 126), reused 223 (delta 114), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (235/235), 42.71 KiB | 1.64 MiB/s, done.\n",
            "Resolving deltas: 100% (126/126), done.\n",
            "/content/thermomaps-ising/thermomaps-root\n",
            "Obtaining file:///content/thermomaps-ising/thermomaps-root\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: thermomaps\n",
            "  Running setup.py develop for thermomaps\n",
            "Successfully installed thermomaps-0.1\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "# Clone repo\n",
        "%cd /content/\n",
        "!rm -rf thermomaps-ising\n",
        "!git clone https://github.com/lherron2/thermomaps-ising.git\n",
        "\n",
        "# Install repo\n",
        "%cd /content/thermomaps-ising/thermomaps-root/\n",
        "!pip install -e .\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import ising\n",
        "import numpy as np\n",
        "from ising.swedsen_wang_simulator import IsingSwendsenWang, Energy, Magnetization\n",
        "from tm.core.Backbone import ConvBackbone\n",
        "from tm.core.DiffusionModel import DiffusionTrainer, SteeredDiffusionSampler\n",
        "from tm.core.DiffusionProcesses import VPDiffusion\n",
        "from tm.core.Loader import Loader\n",
        "from tm.core.Prior import GlobalEquilibriumHarmonicPrior\n",
        "from tm.architectures.UNet2D_mid_attn import Unet2D\n",
        "from tm.core.utils import compute_model_dim"
      ],
      "metadata": {
        "id": "YGLdo7pj4G0C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IsingArgs:\n",
        "  size = 8\n",
        "  warm_up = 1000\n",
        "  steps = 1000\n",
        "  temp = 2\n",
        "  Jx = 1\n",
        "  Jy = 1\n",
        "  sampling_frequency = 10\n",
        "  filename = \"ising\""
      ],
      "metadata": {
        "id": "2M3Ncjce6a4l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, paired_temperatures, trajectory_fluctuation_dict = [], [], {}\n",
        "temperatures = [1,2,3]\n",
        "\n",
        "# Generating data at three temperatures using Swedsen-Wang sampling\n",
        "for sim_idx, temp in enumerate(temperatures):\n",
        "\n",
        "  observables = [Energy(Jx = IsingArgs.Jx, Jy = IsingArgs.Jy), Magnetization()]\n",
        "\n",
        "  # Initialize simulation\n",
        "  sim = IsingSwendsenWang(size = IsingArgs.size, warm_up = IsingArgs.warm_up,\n",
        "                          temp = temp, Jx = 1, Jy = 1)\n",
        "\n",
        "  # Run simulation\n",
        "  results = sim.simulate(steps = IsingArgs.steps, observables = observables,\n",
        "                         sampling_frequency = IsingArgs.sampling_frequency)\n",
        "\n",
        "  # Coordinates are lattice configurations\n",
        "  coordinates = np.expand_dims(results['lattice'], 1)\n",
        "\n",
        "  # Fluctuations are temperatures (coordinates are sampled from the global equilibrium distribution)\n",
        "  fluctuations = np.ones_like(coordinates) * temp\n",
        "\n",
        "  # Form the TM input data by joining coordinates and fluctuations along the channel axis\n",
        "  data = np.concatenate((coordinates, fluctuations), axis=1)\n",
        "\n",
        "  dataset.append(data)\n",
        "\n",
        "  # Each coordinate trajectory was collected at a temperature and has associated fluctuations\n",
        "  # (include sim_idx in case there are repeat temperatures)\n",
        "  trajectory_fluctuation_dict[f\"{temp}_{sim_idx}\"] = fluctuations\n",
        "\n",
        "  # Each coordinate frame is paired with a temperature\n",
        "  temps_arr = np.ones(len(coordinates)) * temp\n",
        "  paired_temperatures.append(temps_arr)\n",
        "\n",
        "dataset = np.concatenate(dataset)\n",
        "paired_temperatures = np.concatenate(paired_temperatures)"
      ],
      "metadata": {
        "id": "dxZbL4uG5LAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The inputs to the `Loader` are the dataset and the temperatures associated with each sample, and control parameters. The control axis is the axis of the data containing the data that is to be controlled. For example, the default of `control_axis = 1` indicates that the control parameters may be retrieved along the channel dimension of the data, assuming the data is of shape `(n_samples, n_channels, x, y)`. In the provided example there are two channels: one containing lattice configurations and another containing the temperatures. Since the temperatures are the second dimension along the `control_axis`, we set `control_dims=(1,2)`. This way, the temperatures can be retrieved using a `loader.control_slice` via `loader.data[loader.control_slice]`.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5Zkuolccxm6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = Loader(data = dataset, temperatures = paired_temperatures,\n",
        "                control_axis = 1, control_dims = (1,2))"
      ],
      "metadata": {
        "id": "4dK81IhFks6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `GlobalEquilibriumHarmonicPrior` (`GEHP`) is responsible for sampling the prior at the correct temperature. The inputs to the `GEHP` is a dictionary `trajectory_fluctuation_dict` containing key-value pairs of generated coordinate trajectories, and the temperatures that the trajectories were generated at."
      ],
      "metadata": {
        "id": "5lIm9PG0x63e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GEHP = GlobalEquilibriumHarmonicPrior(data=trajectory_fluctuation_dict)"
      ],
      "metadata": {
        "id": "lYeYBZ2IzGF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The format required as input for the `GEHP` might seem convoluted, but that is because there is also a `LocalEquilibriumHarmonicPrior` (`LEHP`) that performs the computations associated with fluctuation mapping. This involves computing fluctuations over each trajectory in the input dictionary, and fitting a multi-linear function to the (temperatures, fluctuation) data."
      ],
      "metadata": {
        "id": "-BbjVBfttV2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we initialize the black-box `model(nn.Module)` that will be parameterized during training. In this case, the `model` is a 2D U-net with attention at the bottleneck layer."
      ],
      "metadata": {
        "id": "u8_BVMDB49Gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get model dim that is compatible w/ data shape + possible model shapes.\n",
        "model_dim = compute_model_dim(loader.data_dim, groups=8)\n",
        "model = Unet2D(\n",
        "    dim=model_dim,\n",
        "    dim_mults=(1, 2, 2, 4), # downsampling/upsampling factors before/after bottleneck\n",
        "    resnet_block_groups=8,\n",
        "    self_condition=True, # greatly improves training convergence when data is limited\n",
        "    learned_sinusoidal_cond=True,\n",
        "    channels=2, # two channels for Ising model data\n",
        ")"
      ],
      "metadata": {
        "id": "K5Z-tURH40HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `backbone` is a wrapper class around `model` that contains methods used to load and save models, and automatically upsamples image-structured data to match the dimensions of the model."
      ],
      "metadata": {
        "id": "5TX29TRa5ZD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backbone = ConvBackbone(\n",
        "    model=model,\n",
        "    data_shape=loader.data_dim,\n",
        "    target_shape=model_dim, # data is upsampled to this resolution\n",
        "    num_dims=4, # (n_sample, n_channel, n_x, n_y)\n",
        "    lr=1e-3,\n",
        "    eval_mode=\"train\",\n",
        "    self_condition=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "rxwd0_kV5Ylm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `VPDiffusion` class contains methods to evaluate forward and reverse diffusion kernels for the Variance Preserving diffusion process described in Song (2019)."
      ],
      "metadata": {
        "id": "K7qTJUFO6BhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diffusion = VPDiffusion(num_diffusion_timesteps=100)"
      ],
      "metadata": {
        "id": "siefDC705-Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A `DiffusionTrainer` trains a `backbone` model to reverse the diffusion process (`VPDiffusion`) applied to coordinates (`dataset` in `Loader`). Optionally, the model can be trained to predict the original samples directly (`pred_type=x0`) or the noise used to corrupt the sample (`pred_type=noise`)."
      ],
      "metadata": {
        "id": "fTEen9Ju9XT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = DiffusionTrainer(diffusion, backbone, loader, model_dir='/content/TM/models',\n",
        "                           pred_type='x0', prior=GEHP, device='cuda:0')\n",
        "trainer.train(5, loss_type=\"l2\", batch_size=16, print_freq=10)"
      ],
      "metadata": {
        "id": "GE6hbqb26TFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now sample from the thermodynamic map using the `SteeredDiffusionSampler`. First load the model corresponding to the epoch that you want to sample from, and then pass the `DiffusionProcess`, `Loader`, and `Prior` used to train the model. Optionally, provide a scalar `gamma` that conditions over the fluctuations during the generative process when `gamma=1`. Otherwise, if `gamma=0` the conditional process is carried out for the fluctuations dimensions."
      ],
      "metadata": {
        "id": "esL_gYMWE48S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backbone.load_model('/content/TM/models', epoch=3, device='cuda:0')\n",
        "\n",
        "sampler = SteeredDiffusionSampler(diffusion_process=diffusion, backbone=backbone,\n",
        "                                  loader=loader, sample_dir='/content/TM/models/samples',\n",
        "                                  pred_type='x0', prior=GEHP, gamma=1)\n",
        "\n",
        "# gamma = 1 controls the diffusion of fluctuations based on the provided temperature.\n",
        "# gamma = 0 allows the generative process to be carried out for the fluctuations\n",
        "\n",
        "sampler.sample_loop(num_samples=1000, batch_size=1000, save_prefix='ising',\n",
        "                    temperature=2.2, n_ch=2)\n"
      ],
      "metadata": {
        "id": "cZGrNzVo-Dj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cnSyz7Gpzc5D"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xm5nkv8N_UIS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}